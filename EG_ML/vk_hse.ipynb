{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.read_parquet('data_vk_hse/0000.parquet', engine='fastparquet')\n",
    "df2=pd.read_parquet('data_vk_hse/0001.parquet', engine='fastparquet')\n",
    "df3=pd.read_parquet('data_vk_hse/0002.parquet', engine='fastparquet')\n",
    "df4=pd.read_parquet('data_vk_hse/0003.parquet', engine='fastparquet')\n",
    "df5=pd.read_parquet('data_vk_hse/0004.parquet', engine='fastparquet')\n",
    "df6=pd.read_parquet('data_vk_hse/0005.parquet', engine='fastparquet')\n",
    "df7=pd.read_parquet('data_vk_hse/0006.parquet', engine='fastparquet')\n",
    "df8=pd.read_parquet('data_vk_hse/0007.parquet', engine='fastparquet')\n",
    "df9=pd.read_parquet('data_vk_hse/0008.parquet', engine='fastparquet')\n",
    "df10=pd.read_parquet('data_vk_hse/0009.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat ([df1, df2, df3,df4,df5,df6,df7,df8,df9,df10])\n",
    "feature_to_drop=['title','blocks.data','username','author_id','timestamp', 'id','blocks.type','comments.id','comments.timestamp','comments.parent_id','comments.text_markdown','comments.text_html','comments.images','comments.rating','comments.pluses',\t'comments.minuses','comments.author_id','comments.username','rating','pluses','minuses','url']\n",
    "df.drop(feature_to_drop, axis=1, inplace=True)\n",
    "df = df.explode('tags')\n",
    "import catboost as cb\n",
    "df = df.sample(frac=0.0001) # Get 30% of the data\n",
    "len(df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_markdown</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14729</th>\n",
       "      <td></td>\n",
       "      <td>Комиксы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5633</th>\n",
       "      <td></td>\n",
       "      <td>Км</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9962</th>\n",
       "      <td>План эвакуации в пермской галерее.\\nВ 2020 год...</td>\n",
       "      <td>Фрейд</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7659</th>\n",
       "      <td></td>\n",
       "      <td>Бег</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21616</th>\n",
       "      <td>1\\. Зима. Первый снег.\\nКак всегда, пролежал о...</td>\n",
       "      <td>Жизнь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13668</th>\n",
       "      <td>4 февраля. Демонстрация обманутых вкладчиков п...</td>\n",
       "      <td>Выборы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14195</th>\n",
       "      <td>НИКОГДА, СЛЫШИТЕ?НИКОГДА НЕ ДАВАЙТЕ ДРУЗЬЯМ ДО...</td>\n",
       "      <td>Dota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22971</th>\n",
       "      <td></td>\n",
       "      <td>Политика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30813</th>\n",
       "      <td>UPD!!!!\\nКак только отправила пост, пришло оче...</td>\n",
       "      <td>Сотовые операторы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11326</th>\n",
       "      <td>Утро нас встретило дождём. Приехали на морской...</td>\n",
       "      <td>Море</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text_markdown               tags\n",
       "14729                                                               Комиксы\n",
       "5633                                                                     Км\n",
       "9962   План эвакуации в пермской галерее.\\nВ 2020 год...              Фрейд\n",
       "7659                                                                    Бег\n",
       "21616  1\\. Зима. Первый снег.\\nКак всегда, пролежал о...              Жизнь\n",
       "...                                                  ...                ...\n",
       "13668  4 февраля. Демонстрация обманутых вкладчиков п...             Выборы\n",
       "14195  НИКОГДА, СЛЫШИТЕ?НИКОГДА НЕ ДАВАЙТЕ ДРУЗЬЯМ ДО...               Dota\n",
       "22971                                                              Политика\n",
       "30813  UPD!!!!\\nКак только отправила пост, пришло оче...  Сотовые операторы\n",
       "11326  Утро нас встретило дождём. Приехали на морской...               Море\n",
       "\n",
       "[114 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 4.3414403\ttotal: 1.06s\tremaining: 14m 5s\n",
      "10:\tlearn: 4.1881646\ttotal: 11.5s\tremaining: 13m 48s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 22\u001b[0m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m CatBoostClassifier(\n\u001b[0;32m     14\u001b[0m     depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m     15\u001b[0m     iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m800\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     text_features\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext_markdown\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Предсказания\u001b[39;00m\n\u001b[0;32m     25\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32md:\\работа\\прога\\ii2\\Lib\\site-packages\\catboost\\core.py:5100\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5097\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m   5098\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m-> 5100\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5101\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5102\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\работа\\прога\\ii2\\Lib\\site-packages\\catboost\\core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2315\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m   2325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2328\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32md:\\работа\\прога\\ii2\\Lib\\site-packages\\catboost\\core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1723\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1724\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Предобработка текста\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Разделение данных на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['text_markdown']], df['tags'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Создание модели CatBoost с указанием текстового признака\n",
    "model = CatBoostClassifier(\n",
    "    depth=6,\n",
    "    iterations=10,\n",
    "    learning_rate=0.06,\n",
    "    verbose=10,\n",
    "    text_features=['text_markdown']\n",
    ")\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Предсказания\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Оценка модели\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предсказанный тег: ['Текст']\n"
     ]
    }
   ],
   "source": [
    "def predict_tag(text):\n",
    "    # Подготавливаем входные данные\n",
    "    input_df = pd.DataFrame({'text_markdown': [text]})\n",
    "    \n",
    "    # Предсказываем\n",
    "    predicted_tag = model.predict(input_df)\n",
    "    \n",
    "    return predicted_tag[0]  # Возвращает первый элемент, так как результатом будет одиночный тег\n",
    "\n",
    "# Пример использования\n",
    "predicted_tag = predict_tag('В Иране  началсь война тк слуйчайно выпустили не туда ракету')\n",
    "print(\"Предсказанный тег:\", predicted_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def load_catboost_model(filename):\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(filename, format='cbm')\n",
    "    return model\n",
    "model = load_catboost_model('catboost_model.cbm')   \n",
    "\n",
    "def plot_metrics(model, X_test, y_test):\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        # Предсказываем вероятности\n",
    "        y_scores = model.predict_proba(X_test)\n",
    "\n",
    "        # Получаем список уникальных классов из y_test\n",
    "        unique_classes = np.unique(y_test)\n",
    "        y_test_bin = label_binarize(y_test, classes=unique_classes)\n",
    "        n_classes = y_test_bin.shape[1]\n",
    "\n",
    "        # Вычисляем микро-усредненные значения FPR и TPR\n",
    "        if n_classes == 2:\n",
    "            fpr, tpr, _ = roc_curve(y_test_bin, y_scores[:, 1])\n",
    "        else:\n",
    "            fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_scores.ravel())\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        # Визуализация общей ROC кривой\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, label='Micro-average ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "\n",
    "    # F1 Score и точность\n",
    "    y_pred = model.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"F1 Score:\", 1-f1)\n",
    "    print(\"Accuracy:\", 1-accuracy)\n",
    "\n",
    "plot_metrics(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predicted_tags_with_probabilities(model, X_test):\n",
    "    # Проверяем, поддерживает ли модель predict_proba\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        probabilities = model.predict_proba(X_test)\n",
    "        class_labels = model.classes_\n",
    "        for index, prob in enumerate(probabilities):\n",
    "            print(f\"Sample {index + 1}:\")\n",
    "            for class_index, class_prob in enumerate(prob):\n",
    "                print(f\"   {class_labels[class_index]}: {class_prob:.4f}\")\n",
    "            print(\"\\n\")\n",
    "    else:\n",
    "        print(\"This model does not support probability predictions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_catboost_model(model, filename):\n",
    "    model.save_model(filename, format='cbm')\n",
    "\n",
    "# Пример использования:\n",
    "save_catboost_model(model, 'catboost_model.cbm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def load_catboost_model(filename):\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(filename, format='cbm')\n",
    "    return model\n",
    "\n",
    "# Пример использования:\n",
    "# loaded_catboost_model = load_catboost_model('catboost_model.cbm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "напиши также пожалуйста нейронную сеть на pytorch которая будет обучаться на тексте и таргет бует в виде списка слов в итоге она должна выводить класс с наибольшей вероятностью остальный классы с вероятностями график метрики roc_auc и f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, f1_score, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предполагаем, что `model` - ваша обученная модель CatBoost, а `X_test` и `y_test` - тестовые данные\n",
    "\n",
    "# Предсказания вероятностей\n",
    "y_probs = model.predict_proba(X_test)[:, 1]  # Извлечение вероятностей для положительного класса\n",
    "\n",
    "# Расчет ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, y_probs)\n",
    "print(f\"ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Бинаризация предсказаний для F1-score (порог можно настроить)\n",
    "y_pred = (y_probs >= 0.5).astype(int)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Создание датасета\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "# Определение модели\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 128)\n",
    "        self.conv = nn.Conv1d(128, 256, 5)\n",
    "        self.pool = nn.MaxPool1d(5)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return self.activation(x)\n",
    "\n",
    "# Инициализация модели, оптимизатора и критерия\n",
    "model = TextClassifier(vocab_size=10000, num_classes=20)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Обучение\n",
    "def train(model, dataloader, optimizer, criterion, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for texts, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "# Оценка\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in dataloader:\n",
    "            outputs = model(texts)\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_preds.extend(outputs.numpy())\n",
    "\n",
    "    roc_auc = roc_auc_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, np.round(all_preds), average='macro')\n",
    "    return roc_auc, f1\n",
    "\n",
    "# Дополните данными и дополнительной логикой для демонстрации\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Создание датасета\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = texts\n",
    "        self.labels = torch.Tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "# Определение модели\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, num_classes):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 128)\n",
    "        self.conv = nn.Conv1d(128, 256, 5)\n",
    "        self.pool = nn.MaxPool1d(5)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return self.activation(x)\n",
    "\n",
    "# Инициализация модели, оптимизатора и критерия\n",
    "model = TextClassifier(vocab_size=10000, num_classes=20)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Имитация данных\n",
    "num_samples = 1000\n",
    "vocab_size = 10000\n",
    "num_classes = 20\n",
    "max_length = 50\n",
    "\n",
    "texts = torch.randint(0, vocab_size, (num_samples, max_length))\n",
    "labels = torch.randint(0, 2, (num_samples, num_classes)).float()\n",
    "\n",
    "dataset = TextDataset(texts, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Функция обучения\n",
    "def train(model, dataloader, optimizer, criterion, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for texts, labels in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(texts)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "# Функция оценки\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for texts, labels in dataloader:\n",
    "            outputs = model(texts)\n",
    "            all_labels.append(labels)\n",
    "            all_preds.append(outputs)\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    roc_auc = roc_auc_score(all_labels, all_preds, average='macro')\n",
    "    f1 = f1_score(all_labels, (all_preds > 0.5).astype(int), average='macro')\n",
    "    return roc_auc, f1\n",
    "\n",
    "# Обучение и оценка\n",
    "train(model, dataloader, optimizer, criterion, epochs=5)\n",
    "roc_auc, f1 = evaluate(model, dataloader)\n",
    "print(f'ROC AUC: {roc_auc}, F1 Score: {f1}')\n",
    "\n",
    "# Визуализация результатов\n",
    "def plot_metrics(roc_auc, f1):\n",
    "    metrics = [roc_auc, f1]\n",
    "    labels = ['ROC AUC', 'F1 Score']\n",
    "    plt.bar(labels, metrics, color=['blue', 'green'])\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Performance Metrics')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics(roc_auc, f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Предположим, что texts и tags - это ваши данные\n",
    "texts = [\n",
    "    \"Что можно купить в Китае за цену нового iPhone...\",\n",
    "    \"Осенью в России стартовали продажи очередной модели...\"\n",
    "]\n",
    "tags = [\n",
    "    [\"Китай\", \"AliExpress\", \"Китайские товары\", \"Бизнес\"],\n",
    "    [\"Россия\", \"Продажи\", \"Смартфоны\"]\n",
    "]\n",
    "\n",
    "# Токенизация и преобразование текстов в индексы\n",
    "vocab = {word: idx for idx, word in enumerate(set(' '.join(texts).split()))}\n",
    "indexed_texts = [[vocab[word] for word in text.split()] for text in texts]\n",
    "\n",
    "# Паддинг текстов до одинаковой длины\n",
    "max_len = max(len(text) for text in indexed_texts)\n",
    "padded_texts = [text + [0] * (max_len - len(text)) for text in indexed_texts]\n",
    "\n",
    "# Преобразование тегов в бинарные векторы\n",
    "mlb = MultiLabelBinarizer()\n",
    "binary_tags = mlb.fit_transform(tags)\n",
    "\n",
    "# Создание датасета\n",
    "class TextTagDataset(Dataset):\n",
    "    def __init__(self, texts, tags):\n",
    "        self.texts = torch.LongTensor(texts)\n",
    "        self.tags = torch.FloatTensor(tags)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.tags[idx]\n",
    "\n",
    "# Создание DataLoader\n",
    "dataset = TextTagDataset(padded_texts, binary_tags)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Пример использования DataLoader\n",
    "for text, tag in dataloader:\n",
    "    print(\"Text batch:\", text)\n",
    "    print(\"Tag batch:\", tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Пример данных\n",
    "texts = [\n",
    "    \"Что можно купить в Китае за цену нового iPhone...\",\n",
    "    \"Осенью в России стартовали продажи очередной модели...\"\n",
    "]\n",
    "tags = [\n",
    "    [\"Китай\", \"AliExpress\", \"Китайские товары\", \"Бизнес\"],\n",
    "    [\"Россия\", \"Продажи\", \"Смартфоны\"]\n",
    "]\n",
    "\n",
    "# Токенизация текста\n",
    "def tokenize(texts):\n",
    "    tokenized_texts = [text.lower().split() for text in texts]\n",
    "    word_counts = Counter(word for text in tokenized_texts for word in text)\n",
    "    vocab = {word: i + 1 for i, word in enumerate(word_counts)}  # Индекс 0 зарезервирован для паддинга\n",
    "    indexed_texts = [[vocab[word] for word in text] for text in tokenized_texts]\n",
    "    return vocab, indexed_texts\n",
    "\n",
    "vocab, indexed_texts = tokenize(texts)\n",
    "padded_texts = pad_sequence([torch.tensor(text) for text in indexed_texts], batch_first=True, padding_value=0)\n",
    "\n",
    "# Динамическое преобразование тегов\n",
    "mlb = MultiLabelBinarizer()\n",
    "binary_tags = mlb.fit_transform(tags)\n",
    "\n",
    "# Создание датасета\n",
    "class TextTagDataset(Dataset):\n",
    "    def __init__(self, texts, tags):\n",
    "        self.texts = texts\n",
    "        self.tags = torch.FloatTensor(tags)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx], self.tags[idx]\n",
    "\n",
    "dataset = TextTagDataset(padded_texts, binary_tags)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Вывод данных из DataLoader\n",
    "for text, tag in dataloader:\n",
    "    print(\"Text batch:\", text)\n",
    "    print(\"Tag batch:\", tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Сохраняем DataFrame в CSV файл, чтобы использовать с torchtext\n",
    "df.to_csv('data.csv', index=False)\n",
    "\n",
    "# Определяем поля\n",
    "TEXT = Field(sequential=True, tokenize='spacy', lower=True)\n",
    "LABEL = Field(sequential=False, is_target=True)\n",
    "\n",
    "# Создаем датасет\n",
    "fields = {'text': ('text', TEXT), 'tags': ('label', LABEL)}\n",
    "dataset = TabularDataset(path='data.csv', format='csv', fields=fields)\n",
    "\n",
    "# Построим словарь\n",
    "TEXT.build_vocab(dataset, max_size=10000, min_freq=2)\n",
    "LABEL.build_vocab(dataset)\n",
    "\n",
    "# Итераторы для обучения\n",
    "batch_size = 32\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iterator, valid_iterator = BucketIterator.splits(\n",
    "    (dataset, dataset), batch_size=batch_size, device=device, sort_within_batch=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        embedded = embedded.mean(dim=0)  # Среднее значение эмбеддингов\n",
    "        hidden = self.relu(self.fc(embedded))\n",
    "        output = self.fc2(hidden)\n",
    "        return output\n",
    "\n",
    "# Инициализация модели\n",
    "vocab_size = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim = len(LABEL.vocab)\n",
    "\n",
    "model = TextClassifier(vocab_size, embedding_dim, hidden_dim, output_dim).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Обучение модели\n",
    "def train_model(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# Запуск обучения\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_model(model, train_iterator, optimizer, criterion)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} Loss: {train_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "CatBoostError",
     "evalue": "C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/model/model_export/model_exporter.cpp:152: Can save model with text features only in cbm format",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39mload_catboost_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcatboost_model.cbm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Сохранение модели в формате JSON\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel1.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjson\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\работа\\прога\\ii2\\Lib\\site-packages\\catboost\\core.py:3310\u001b[0m, in \u001b[0;36mCatBoost.save_model\u001b[1;34m(self, fname, format, export_parameters, pool)\u001b[0m\n\u001b[0;32m   3303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, Pool):\n\u001b[0;32m   3304\u001b[0m     pool \u001b[38;5;241m=\u001b[39m Pool(\n\u001b[0;32m   3305\u001b[0m         data\u001b[38;5;241m=\u001b[39mpool,\n\u001b[0;32m   3306\u001b[0m         cat_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cat_feature_indices() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, FeaturesData) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3307\u001b[0m         text_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_text_feature_indices() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, FeaturesData) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   3308\u001b[0m         embedding_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_embedding_feature_indices() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, FeaturesData) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3309\u001b[0m     )\n\u001b[1;32m-> 3310\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\работа\\прога\\ii2\\Lib\\site-packages\\catboost\\core.py:1813\u001b[0m, in \u001b[0;36m_CatBoostBase._save_model\u001b[1;34m(self, output_file, format, export_parameters, pool)\u001b[0m\n\u001b[0;32m   1810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m export_parameters:\n\u001b[0;32m   1811\u001b[0m     params_string \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(export_parameters, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m_NumpyAwareEncoder)\n\u001b[1;32m-> 1813\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m_catboost.pyx:5020\u001b[0m, in \u001b[0;36m_catboost._CatBoost._save_model\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:5032\u001b[0m, in \u001b[0;36m_catboost._CatBoost._save_model\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCatBoostError\u001b[0m: C:/Go_Agent/pipelines/BuildMaster/catboost.git/catboost/libs/model/model_export/model_exporter.cpp:152: Can save model with text features only in cbm format"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def load_catboost_model(filename):\n",
    "    model = CatBoostClassifier()\n",
    "    model.load_model(filename, format='cbm')\n",
    "    return model\n",
    "# Загрузка модели из файла .cbm\n",
    "model =load_catboost_model('catboost_model.cbm')\n",
    "\n",
    "# Сохранение модели в формате JSON\n",
    "model.save_model('model1.json', format='json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ii2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
